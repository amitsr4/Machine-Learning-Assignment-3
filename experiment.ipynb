{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "losssVyCwLEw"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn import preprocessing, model_selection, linear_model, ensemble\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from xgboost import XGBRegressor\n",
        "from sklearn.metrics import make_scorer, mean_squared_error, mean_absolute_error, r2_score\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "import sklearn.base as skb\n",
        "from sklearn.impute import SimpleImputer\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSl0A_UwwdWf",
        "outputId": "cbcb42a8-9c99-4b1e-d43e-52e95c101e3e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n",
            "/content/drive/MyDrive/Studies/Practical Machine Learning/Assignment 3\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd /content/drive/MyDrive/'Studies/Practical Machine Learning/Assignment 3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QB2yc0sfwMBg"
      },
      "outputs": [],
      "source": [
        "# Function to load dataset and partition it into train, dev, and test sets\n",
        "def load_dataset(filename):\n",
        "    data = pd.read_pickle(filename, compression='infer')\n",
        "\n",
        "    # Splitting dataset into train, dev, and test sets\n",
        "    train_set = data['train'].drop('target', axis=1), data['train']['target']\n",
        "    dev_set = data['dev'].drop('target', axis=1), data['dev']['target']\n",
        "    test_set = data['test'].drop('target', axis=1), data['test']['target']\n",
        "\n",
        "    return train_set, dev_set, test_set\n",
        "\n",
        "train, dev, test = load_dataset('ass3.pickle')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kbcP22scwNhF",
        "outputId": "e295c915-dcc1-418e-d738-1d25146515a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of train samples: 12384\n",
            "Number of dev samples: 4128\n",
            "Number of test samples: 4128\n",
            "Number of features: 8\n",
            "\n",
            "First few records of the training dataset:\n",
            "           f0    f1        f2        f3      f4        f5     f6      f7\n",
            "14981  4.0391  15.0  6.297710  0.992366   334.0  2.549618  32.72 -116.99\n",
            "6614   4.7241  46.0  5.375758  0.954545   753.0  2.281818  34.17 -118.10\n",
            "14233  3.3553   7.0  5.229213  1.101124  1304.0  2.930337  32.70 -117.01\n",
            "1802   1.3929  52.0  5.000000  0.953488   126.0  2.930233  37.92 -122.36\n",
            "6030   1.6006  52.0  4.427083  1.017361  1246.0  2.163194  34.07 -117.75\n",
            "\n",
            "Statistical Summary:\n",
            "                 f0            f1            f2            f3            f4  \\\n",
            "count  12210.000000  12244.000000  12226.000000  12228.000000  12215.000000   \n",
            "mean       3.872771     28.630595      5.420978      1.096626   1426.830618   \n",
            "std        1.919183     12.566127      2.382548      0.471398   1103.528284   \n",
            "min        0.499900      1.000000      0.846154      0.500000      3.000000   \n",
            "25%        2.555600     18.000000      4.430232      1.006386    786.000000   \n",
            "50%        3.534100     29.000000      5.218429      1.049202   1170.000000   \n",
            "75%        4.745975     37.000000      6.043349      1.099202   1739.000000   \n",
            "max       15.000100     52.000000    132.533333     34.066667  28566.000000   \n",
            "\n",
            "                 f5            f6            f7  \n",
            "count  12242.000000  12233.000000  12236.000000  \n",
            "mean       3.144714     35.626833   -119.561040  \n",
            "std       13.440452      2.133539      1.996646  \n",
            "min        0.692308     32.550000   -124.350000  \n",
            "25%        2.428571     33.940000   -121.790000  \n",
            "50%        2.816384     34.250000   -118.490000  \n",
            "75%        3.276456     37.710000   -118.020000  \n",
            "max     1243.333333     41.950000   -114.550000  \n",
            "\n",
            "Missing Values:\n",
            "f0    174\n",
            "f1    140\n",
            "f2    158\n",
            "f3    156\n",
            "f4    169\n",
            "f5    142\n",
            "f6    151\n",
            "f7    148\n",
            "dtype: int64\n"
          ]
        }
      ],
      "source": [
        "# Show dataset details\n",
        "print(f\"Number of train samples: {train[0].shape[0]}\")\n",
        "print(f\"Number of dev samples: {dev[0].shape[0]}\")\n",
        "print(f\"Number of test samples: {test[0].shape[0]}\")\n",
        "print(f\"Number of features: {train[0].shape[1]}\")\n",
        "\n",
        "print(\"\\nFirst few records of the training dataset:\")\n",
        "print(train[0].head())\n",
        "print(\"\\nStatistical Summary:\")\n",
        "print(train[0].describe())\n",
        "print(\"\\nMissing Values:\")\n",
        "print(train[0].isnull().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a3uabX8SwPUj"
      },
      "outputs": [],
      "source": [
        "# Function to preprocess data: impute missing values and scale the features\n",
        "def preprocess_data(train, dev, test):\n",
        "    # Impute missing values\n",
        "    imputer = SimpleImputer(strategy='mean')\n",
        "    imputer.fit(train[0])\n",
        "\n",
        "    train_imputed = imputer.transform(train[0]), train[1]\n",
        "    dev_imputed = imputer.transform(dev[0]), dev[1]\n",
        "    test_imputed = imputer.transform(test[0]), test[1]\n",
        "\n",
        "    # Scaling the data\n",
        "    scaler = preprocessing.StandardScaler().fit(train_imputed[0])\n",
        "    train_scaled = scaler.transform(train_imputed[0]), train_imputed[1]\n",
        "    dev_scaled = scaler.transform(dev_imputed[0]), dev_imputed[1]\n",
        "    test_scaled = scaler.transform(test_imputed[0]), test_imputed[1]\n",
        "\n",
        "    return train_scaled, dev_scaled, test_scaled\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoVO0dZKwQQl"
      },
      "outputs": [],
      "source": [
        "# Preprocess data\n",
        "train_scaled, dev_scaled, test_scaled = preprocess_data(train, dev, test)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Dw0jRCf1wSIQ"
      },
      "outputs": [],
      "source": [
        "# Define function to train and validate models\n",
        "def run_experiment(name, train, dev, regressors, metrics_dict):\n",
        "    print(f'****** {name} ******')\n",
        "    for regressor_name, regressor in regressors:\n",
        "        model = skb.clone(regressor)\n",
        "        # Perform 5-fold cross-validation\n",
        "        cv_results = model_selection.cross_validate(model, *train, cv=5, scoring=metrics_dict, return_train_score=True)\n",
        "\n",
        "        # Get mean of the scores from cross-validation for both train and test\n",
        "        mean_train_scores = {name: np.mean(scores) for name, scores in cv_results.items() if name.startswith('train_')}\n",
        "        mean_test_scores = {name: np.mean(scores) for name, scores in cv_results.items() if name.startswith('test_')}\n",
        "        print(f'{regressor_name} model achieved {mean_train_scores} on training data and {mean_test_scores} on validation data')\n",
        "\n",
        "        model.fit(*train)\n",
        "        dev_pred = model.predict(dev[0])\n",
        "\n",
        "        dev_scores = {name: scorer._score_func(dev[1], dev_pred) for name, scorer in metrics_dict.items()}\n",
        "        print(f'Dev Results: {dev_scores}')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QBZmXqhywTQd"
      },
      "outputs": [],
      "source": [
        "regressors = [\n",
        "    ('LR', linear_model.LinearRegression()),\n",
        "    ('KNR', KNeighborsRegressor()),\n",
        "    ('SVR', SVR()),\n",
        "    ('RFR', ensemble.RandomForestRegressor(n_estimators=400)),\n",
        "    ('XGBR', XGBRegressor())\n",
        "]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d1mp_boAwU29"
      },
      "outputs": [],
      "source": [
        "metrics_dict = {\n",
        "    'MSE': make_scorer(mean_squared_error, greater_is_better=False),\n",
        "    'MAE': make_scorer(mean_absolute_error),\n",
        "    'R2': make_scorer(r2_score)\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n9QPTMbWwV_t",
        "outputId": "aedd94b1-5203-4073-c740-493cf01983c7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "****** After scaling ******\n",
            "LR model achieved {'train_MSE': -0.5462225250920477, 'train_MAE': 0.5435008895158063, 'train_R2': 0.5854222776391872} on training data and {'test_MSE': -0.5533573566623324, 'test_MAE': 0.5441936203890856, 'test_R2': 0.5797157883272115} on validation data\n",
            "Dev Results: {'MSE': 0.522904334901607, 'MAE': 0.5231571750489642, 'R2': 0.6008414936534726}\n",
            "KNR model achieved {'train_MSE': -0.3055871694785036, 'train_MAE': 0.37987147372654095, 'train_R2': 0.7680644462796943} on training data and {'test_MSE': -0.467385240865742, 'test_MAE': 0.47015424484436136, 'test_R2': 0.6451492193180905} on validation data\n",
            "Dev Results: {'MSE': 0.44115472085138757, 'MAE': 0.4567328284883721, 'R2': 0.6632449806026308}\n",
            "SVR model achieved {'train_MSE': -0.379053913330189, 'train_MAE': 0.4078369025808728, 'train_R2': 0.7122964087306171} on training data and {'test_MSE': -0.3935236972857756, 'test_MAE': 0.4196603163135103, 'test_R2': 0.7011749255289784} on validation data\n",
            "Dev Results: {'MSE': 0.3718693531845113, 'MAE': 0.4042797353534498, 'R2': 0.7161338974152716}\n",
            "RFR model achieved {'train_MSE': -0.039234404867473247, 'train_MAE': 0.13088004705351436, 'train_R2': 0.9702212612773303} on training data and {'test_MSE': -0.28661399269701365, 'test_MAE': 0.3544012476588356, 'test_R2': 0.7823957496584792} on validation data\n",
            "Dev Results: {'MSE': 0.26574188271983745, 'MAE': 0.3394993599079462, 'R2': 0.7971461969231451}\n",
            "XGBR model achieved {'train_MSE': -0.06108029213597077, 'train_MAE': 0.17619408303020578, 'train_R2': 0.95363921929678} on training data and {'test_MSE': -0.2560584318382979, 'test_MAE': 0.3390173835336098, 'test_R2': 0.8055896293814737} on validation data\n",
            "Dev Results: {'MSE': 0.23221194330511932, 'MAE': 0.32462535615801813, 'R2': 0.8227412429791064}\n"
          ]
        }
      ],
      "source": [
        "run_experiment(\"After scaling\", train_scaled, dev_scaled, regressors, metrics_dict)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "j9M4zRfIwXKv",
        "outputId": "cb84a8a0-328f-42a5-86af-8cbe9f778e6b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 54 candidates, totalling 162 fits\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/joblib/externals/loky/process_executor.py:700: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [20, 30, 40],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [400, 800]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={&#x27;max_depth&#x27;: [20, 30, 40],\n",
              "                         &#x27;min_samples_leaf&#x27;: [1, 2, 4],\n",
              "                         &#x27;min_samples_split&#x27;: [2, 5, 10],\n",
              "                         &#x27;n_estimators&#x27;: [400, 800]},\n",
              "             scoring=&#x27;neg_mean_squared_error&#x27;, verbose=2)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestRegressor</label><div class=\"sk-toggleable__content\"><pre>RandomForestRegressor()</pre></div></div></div></div></div></div></div></div></div></div>"
            ],
            "text/plain": [
              "GridSearchCV(cv=3, estimator=RandomForestRegressor(), n_jobs=-1,\n",
              "             param_grid={'max_depth': [20, 30, 40],\n",
              "                         'min_samples_leaf': [1, 2, 4],\n",
              "                         'min_samples_split': [2, 5, 10],\n",
              "                         'n_estimators': [400, 800]},\n",
              "             scoring='neg_mean_squared_error', verbose=2)"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "param_grid = {\n",
        "    'n_estimators': [400, 800],\n",
        "    'max_depth': [20,30, 40],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4]\n",
        "}\n",
        "\n",
        "rfr = ensemble.RandomForestRegressor()\n",
        "\n",
        "grid_search = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=3, scoring='neg_mean_squared_error', verbose=2, n_jobs=-1)\n",
        "\n",
        "grid_search.fit(train_scaled[0], train_scaled[1])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X50x0IMp1BaX",
        "outputId": "c9469e6f-9d78-444e-894d-06951c3aa230"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best parameters: {'max_depth': 40, 'min_samples_leaf': 2, 'min_samples_split': 2, 'n_estimators': 800}\n",
            "MSE of the best model on dev set: 0.267295816013345\n",
            "MAE of the best model on dev set: 0.34064462633023634\n",
            "R2 score of the best model on dev set: 0.7959600034820153\n"
          ]
        }
      ],
      "source": [
        "best_params = grid_search.best_params_\n",
        "print(f\"Best parameters: {best_params}\")\n",
        "\n",
        "# Using the best model\n",
        "best_grid = grid_search.best_estimator_\n",
        "\n",
        "# Predicting on the dev set\n",
        "dev_pred = best_grid.predict(dev_scaled[0])\n",
        "\n",
        "mse = mean_squared_error(dev_scaled[1], dev_pred)\n",
        "mae = mean_absolute_error(dev_scaled[1], dev_pred)\n",
        "r2 = r2_score(dev_scaled[1], dev_pred)\n",
        "print(f\"MSE of the best model on dev set: {mse}\")\n",
        "print(f\"MAE of the best model on dev set: {mae}\")\n",
        "print(f\"R2 score of the best model on dev set: {r2}\")\n",
        "\n",
        "# Evaluate on the test set\n",
        "test_pred = best_grid.predict(test_scaled[0])\n",
        "mse_test = mean_squared_error(test_scaled[1], test_pred)\n",
        "mae_test = mean_absolute_error(test_scaled[1], test_pred)\n",
        "r2_test = r2_score(test_scaled[1], test_pred)\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}